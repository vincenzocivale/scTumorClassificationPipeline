{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "j_PgSRoiGacM"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import load_dataset, ClassLabel, load_from_disk\n",
    "from transformers import Trainer, TrainingArguments, default_data_collator\n",
    "from huggingface_hub import login\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import torch.nn.functional as F\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import wandb\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:1\n"
     ]
    }
   ],
   "source": [
    "# Set device to use the second GPU (GPU 1)\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set environment variable to use GPU 1\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "f7d495WEHa3S"
   },
   "outputs": [],
   "source": [
    "SUB_GROUP = \"Lung\"\n",
    "TARGET_COLUMN = \"cell_type\"\n",
    "PERCENTAGE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk(f\"/equilibrium/datasets/TCGA-histological-data/huggingface/lung_embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsampling split 'train' (size: 829567) by 100.00%...\n",
      "Subsampling split 'validation' (size: 331826) by 100.00%...\n",
      "Subsampling split 'test' (size: 497741) by 100.00%...\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "from typing import Union, Dict\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "def subsample_stratified(\n",
    "    data: Union[Dataset, DatasetDict],\n",
    "    label_column: str,\n",
    "    sampling_percentage: float,\n",
    "    seed: int = 42\n",
    ") -> Union[Dataset, DatasetDict]:\n",
    "    \"\"\"\n",
    "    Subsamples a Hugging Face Dataset or each split of a DatasetDict,\n",
    "    maintaining the original label distribution (stratified sampling).\n",
    "\n",
    "    Args:\n",
    "        data (Union[Dataset, DatasetDict]): The input Dataset or DatasetDict.\n",
    "        label_column (str): The name of the column containing the labels.\n",
    "        sampling_percentage (float): The percentage (0.0 to 1.0) of the original\n",
    "                                     size to sample for each split/dataset.\n",
    "        seed (int): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        Union[Dataset, DatasetDict]: A new Dataset or DatasetDict with subsampled data.\n",
    "    \"\"\"\n",
    "    if not (0 < sampling_percentage <= 1.0):\n",
    "        raise ValueError(\"sampling_percentage must be between 0.0 (exclusive) and 1.0 (inclusive).\")\n",
    "\n",
    "    random.seed(seed)\n",
    "\n",
    "    def _subsample_single_dataset(ds: Dataset) -> Dataset:\n",
    "        labels = ds[label_column]\n",
    "        indices_by_label = Counter()\n",
    "        for i, label in enumerate(labels):\n",
    "            indices_by_label.setdefault(label, []).append(i)\n",
    "\n",
    "        selected_indices = []\n",
    "        for label, indices in indices_by_label.items():\n",
    "            num_samples_for_label = max(1, int(len(indices) * sampling_percentage))\n",
    "            num_samples_for_label = min(num_samples_for_label, len(indices)) # Don't oversample\n",
    "            selected_indices.extend(random.sample(indices, num_samples_for_label))\n",
    "\n",
    "        random.shuffle(selected_indices) # Shuffle to mix up order\n",
    "        return ds.select(selected_indices)\n",
    "\n",
    "    if isinstance(data, Dataset):\n",
    "        print(f\"Subsampling single dataset (size: {len(data)}) by {sampling_percentage*100:.2f}%...\")\n",
    "        return _subsample_single_dataset(data)\n",
    "    elif isinstance(data, DatasetDict):\n",
    "        subsampled_dict = DatasetDict()\n",
    "        for split_name, ds in data.items():\n",
    "            print(f\"Subsampling split '{split_name}' (size: {len(ds)}) by {sampling_percentage*100:.2f}%...\")\n",
    "            subsampled_dict[split_name] = _subsample_single_dataset(ds)\n",
    "        return subsampled_dict\n",
    "    else:\n",
    "        raise TypeError(\"Input 'data' must be a Hugging Face Dataset or DatasetDict.\")\n",
    "\n",
    "dataset = subsample_stratified(\n",
    "        dataset,\n",
    "        label_column=\"cell_type\",\n",
    "        sampling_percentage=PERCENTAGE,  \n",
    "        seed=42\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "I42JvQYs2I8m"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classi uniche: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "Numero classi: 50\n",
      "Pesi per classe: tensor([7.2969e+00, 8.8103e+00, 3.3410e+00, 2.4312e+00, 7.0699e+01, 1.5349e+02,\n",
      "        1.1879e+01, 1.0000e+00, 7.2086e+00, 1.2236e+02, 3.1576e+01, 4.3170e+02,\n",
      "        4.2780e+00, 4.2519e+00, 5.4856e+00, 1.9107e+02, 1.1707e+02, 3.1308e+00,\n",
      "        2.1146e+01, 2.4837e+01, 2.5255e+02, 4.4563e+03, 1.5332e+02, 3.3216e+01,\n",
      "        2.3655e+01, 1.2958e+01, 1.2214e+02, 1.9402e+02, 2.4434e+00, 3.7236e+01,\n",
      "        1.4345e+02, 3.8183e+00, 5.7040e+00, 1.0523e+01, 8.3446e+00, 7.4957e+01,\n",
      "        1.5231e+02, 8.5523e+00, 1.7630e+00, 1.8765e+01, 8.4235e+02, 2.3210e+00,\n",
      "        4.9603e+01, 1.1034e+02, 1.5452e+02, 4.9872e+02, 2.3218e+02, 9.9600e+01,\n",
      "        1.6568e+01, 8.6470e+00])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "\n",
    "def compute_class_weights_multiclass(labels, num_classes: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Calcola i pesi per una classificazione multi-class (CrossEntropy)\n",
    "\n",
    "    Args:\n",
    "        labels (array-like): array/list/tensor 1D con i target [0, 1, 2, ...]\n",
    "        num_classes (int): numero totale di classi\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: pesi normalizzati per ogni classe (shape: [num_classes])\n",
    "    \"\"\"\n",
    "    # Converti in torch.Tensor per uniformità\n",
    "    if not isinstance(labels, torch.Tensor):\n",
    "        labels = torch.tensor(labels)\n",
    "\n",
    "    counts = torch.bincount(labels, minlength=num_classes).float()\n",
    "    counts = torch.clamp(counts, min=1.0)  # Evita divisioni per zero\n",
    "\n",
    "    weights = len(labels) / (num_classes * counts)\n",
    "    weights = weights / weights.min()  # Normalizza (peso minimo = 1.0)\n",
    "\n",
    "    return weights\n",
    "\n",
    "\n",
    "all_labels = dataset[\"train\"][TARGET_COLUMN]  # Evita dataset[\"train\"][:]\n",
    "\n",
    "# Calcola numero classi automaticamente\n",
    "num_classes = len(np.unique(all_labels))\n",
    "\n",
    "\n",
    "# Mostra info base\n",
    "print(f\"Classi uniche: {np.unique(all_labels)}\")\n",
    "print(f\"Numero classi: {num_classes}\")\n",
    "\n",
    "# Calcola pesi\n",
    "class_weights = compute_class_weights_multiclass(all_labels, num_classes)\n",
    "\n",
    "# Loss con pesi\n",
    "loss_fn = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# Per debug\n",
    "print(f\"Pesi per classe: {class_weights}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassLabel(names=['B cell', 'CD1c-positive myeloid dendritic cell', 'CD4-positive, alpha-beta T cell', 'CD8-positive, alpha-beta T cell', 'T cell', 'acinar cell', 'alveolar adventitial fibroblast', 'alveolar macrophage', 'alveolar type 1 fibroblast cell', 'bronchial goblet cell', 'bronchus fibroblast of lung', 'brush cell of tracheobronchial tree', 'capillary endothelial cell', 'classical monocyte', 'club cell', 'conventional dendritic cell', 'dendritic cell', 'elicited macrophage', 'endothelial cell of lymphatic vessel', 'epithelial cell of lower respiratory tract', 'fibroblast', 'hematopoietic stem cell', 'ionocyte', 'lung macrophage', 'lung pericyte', 'mast cell', 'mesothelial cell', 'mucus secreting cell', 'multiciliated columnar cell of tracheobronchial tree', 'multiciliated epithelial cell', 'myofibroblast cell', 'nasal mucosa goblet cell', 'natural killer cell', 'non-classical monocyte', 'plasma cell', 'plasmacytoid dendritic cell', 'pulmonary alveolar epithelial cell', 'pulmonary alveolar type 1 cell', 'pulmonary alveolar type 2 cell', 'pulmonary artery endothelial cell', 'pulmonary neuroendocrine cell', 'respiratory basal cell', 'respiratory tract hillock cell', 'serous secreting cell', 'smooth muscle cell', 'stromal cell', 'tracheobronchial goblet cell', 'tracheobronchial serous cell', 'tracheobronchial smooth muscle cell', 'vein endothelial cell'], id=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'].features['cell_type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "4f4hvk5h8A-g"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Optional, Union\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, dim, dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Linear(dim, dim),\n",
    "            nn.BatchNorm1d(dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "\n",
    "class ResidualMLPConv1D(nn.Module):\n",
    "    def __init__(\n",
    "        self, input_dim, hidden_dims, output_dim,\n",
    "        dropout_rate=0.2, use_residual=True,\n",
    "        use_conv=True, conv_channels=64, kernel_size=3\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.use_conv = use_conv\n",
    "\n",
    "        # Normalizzazione iniziale\n",
    "        self.input_bn = nn.BatchNorm1d(input_dim)\n",
    "\n",
    "        # Blocco convoluzionale opzionale\n",
    "        if use_conv:\n",
    "            self.conv_block = nn.Sequential(\n",
    "                nn.Conv1d(1, conv_channels, kernel_size=kernel_size, padding=kernel_size // 2),\n",
    "                nn.BatchNorm1d(conv_channels),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Conv1d(conv_channels, 1, kernel_size=kernel_size, padding=kernel_size // 2),\n",
    "                nn.BatchNorm1d(1),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "\n",
    "        # Primo layer MLP\n",
    "        self.first_layer = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dims[0]),\n",
    "            nn.BatchNorm1d(hidden_dims[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "\n",
    "        # Blocchi nascosti\n",
    "        hidden_layers = []\n",
    "        for i in range(len(hidden_dims) - 1):\n",
    "            if use_residual and hidden_dims[i] == hidden_dims[i + 1]:\n",
    "                hidden_layers.append(ResidualBlock(hidden_dims[i], dropout_rate))\n",
    "            else:\n",
    "                hidden_layers.extend([\n",
    "                    nn.Linear(hidden_dims[i], hidden_dims[i + 1]),\n",
    "                    nn.BatchNorm1d(hidden_dims[i + 1]),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(dropout_rate)\n",
    "                ])\n",
    "        self.hidden_layers = nn.Sequential(*hidden_layers)\n",
    "\n",
    "        # Bottleneck + output\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Linear(hidden_dims[-1], hidden_dims[-1] // 2),\n",
    "            nn.BatchNorm1d(hidden_dims[-1] // 2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.output_layer = nn.Linear(hidden_dims[-1] // 2, output_dim)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: torch.Tensor,\n",
    "        labels: Optional[torch.Tensor] = None,\n",
    "        **kwargs\n",
    "    ) -> dict:\n",
    "        x = self.input_bn(input_ids)\n",
    "\n",
    "        if self.use_conv:\n",
    "            x = x.unsqueeze(1)  # [B, 1, D]\n",
    "            x = self.conv_block(x)\n",
    "            x = x.squeeze(1)    # [B, D]\n",
    "\n",
    "        x = self.first_layer(x)\n",
    "        x = self.hidden_layers(x)\n",
    "        x = self.bottleneck(x)\n",
    "        logits = self.output_layer(x)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss = F.cross_entropy(logits, labels)\n",
    "\n",
    "        return {\"loss\": loss, \"logits\": logits} if loss is not None else {\"logits\": logits}\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear) or isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "it2M1Ms-GId1"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Optional, List\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "\n",
    "\n",
    "class MLPBlock(nn.Module):\n",
    "    def __init__(self, input_dim: int, output_dim: int, dropout_rate: float = 0.2, use_residual: bool = False):\n",
    "        super().__init__()\n",
    "        self.use_residual = use_residual and (input_dim == output_dim)\n",
    "\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        self.bn = nn.BatchNorm1d(output_dim)\n",
    "        self.activation = nn.GELU()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        identity = x\n",
    "        x = self.linear(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.dropout(x)\n",
    "        if self.use_residual:\n",
    "            x = x + identity\n",
    "        return x\n",
    "\n",
    "\n",
    "class AdvancedMLPClassifier(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        hidden_dims: List[int],\n",
    "        output_dim: int,\n",
    "        dropout_rate: float = 0.2,\n",
    "        use_residual_in_hidden: bool = True,\n",
    "        loss_fn: Optional[nn.Module] = None\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "\n",
    "        self.initial_bn = nn.BatchNorm1d(input_dim)\n",
    "\n",
    "        all_dims = [input_dim] + hidden_dims\n",
    "        mlp_layers = []\n",
    "        for i in range(len(all_dims) - 1):\n",
    "            mlp_layers.append(\n",
    "                MLPBlock(\n",
    "                    input_dim=all_dims[i],\n",
    "                    output_dim=all_dims[i + 1],\n",
    "                    dropout_rate=dropout_rate,\n",
    "                    use_residual=use_residual_in_hidden and (all_dims[i] == all_dims[i + 1])\n",
    "                )\n",
    "            )\n",
    "        self.hidden_network = nn.Sequential(*mlp_layers)\n",
    "        self.output_projection = nn.Linear(all_dims[-1], output_dim)\n",
    "        self.loss_fn = loss_fn if loss_fn is not None else nn.CrossEntropyLoss()\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: torch.Tensor,\n",
    "        labels: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        token_type_ids: Optional[torch.Tensor] = None,\n",
    "        return_dict: Optional[bool] = True,\n",
    "        **kwargs\n",
    "    ) -> SequenceClassifierOutput:\n",
    "\n",
    "        if input_ids.ndim > 2:\n",
    "            input_ids = input_ids.view(input_ids.size(0), -1)  # Flatten if necessary\n",
    "\n",
    "        x = self.initial_bn(input_ids)\n",
    "        x = self.hidden_network(x)\n",
    "        logits = self.output_projection(x)\n",
    "\n",
    "        loss = self.loss_fn(logits, labels) if labels is not None else None\n",
    "\n",
    "        if not return_dict:\n",
    "            return (logits, loss) if loss is not None else (logits,)\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=None,\n",
    "            attentions=None\n",
    "        )\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "j6IeXhiKmIpl"
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, dim, dropout_rate=0.2):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Linear(dim, dim),\n",
    "            nn.BatchNorm1d(dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(dim, dim),\n",
    "            nn.BatchNorm1d(dim)\n",
    "        )\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.block(x)\n",
    "        out += residual  # Connessione residuale\n",
    "        return self.relu(out)\n",
    "\n",
    "class ResidualMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims, output_dim, dropout_rate=0.2, use_residual=True):\n",
    "        super(ResidualMLP, self).__init__()\n",
    "\n",
    "        # Input normalization\n",
    "        self.input_bn = nn.BatchNorm1d(input_dim)\n",
    "\n",
    "        # Prima layer con dimensione differente\n",
    "        self.first_layer = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dims[0]),\n",
    "            nn.BatchNorm1d(hidden_dims[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "\n",
    "        # Blocchi nascosti\n",
    "        hidden_layers = []\n",
    "        for i in range(len(hidden_dims) - 1):\n",
    "            if use_residual and hidden_dims[i] == hidden_dims[i+1]:\n",
    "                hidden_layers.append(ResidualBlock(hidden_dims[i], dropout_rate))\n",
    "            else:\n",
    "                hidden_layers.append(nn.Linear(hidden_dims[i], hidden_dims[i+1]))\n",
    "                hidden_layers.append(nn.BatchNorm1d(hidden_dims[i+1]))\n",
    "                hidden_layers.append(nn.ReLU())\n",
    "                hidden_layers.append(nn.Dropout(dropout_rate))\n",
    "\n",
    "        self.hidden_layers = nn.Sequential(*hidden_layers)\n",
    "\n",
    "        # Layer di output con una piccola bottleneck prima della classificazione\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Linear(hidden_dims[-1], hidden_dims[-1] // 2),\n",
    "            nn.BatchNorm1d(hidden_dims[-1] // 2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.output_layer = nn.Linear(hidden_dims[-1] // 2, output_dim)\n",
    "\n",
    "        # Inizializzazione dei pesi più efficace\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, input_ids, labels=None):\n",
    "        x = self.input_bn(input_ids)\n",
    "        x = self.first_layer(x)\n",
    "        x = self.hidden_layers(x)\n",
    "        x = self.bottleneck(x)\n",
    "        logits = self.output_layer(x)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            # Utilizziamo focale loss per gestire meglio classi sbilanciate\n",
    "            if hasattr(self, 'loss_fn'):\n",
    "                loss = self.loss_fn(logits, labels)\n",
    "            else:\n",
    "                loss = nn.CrossEntropyLoss()(logits, labels)\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "E0c70YY6MxFP"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Optional, List\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "\n",
    "class LayerScale(nn.Module):\n",
    "    def __init__(self, dim: int, init_value: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.scale = nn.Parameter(init_value * torch.ones(dim))\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return x * self.scale\n",
    "\n",
    "class ImprovedMLPBlock3(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        output_dim: int,\n",
    "        dropout_rate: float = 0.3,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # layer\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        # layer scale\n",
    "        self.ls = LayerScale(output_dim, init_value=0.1)\n",
    "        # batch norm + activation + dropout\n",
    "        self.bn = nn.BatchNorm1d(output_dim)\n",
    "        self.act = nn.GELU()\n",
    "        self.drop = nn.Dropout(dropout_rate)\n",
    "        # identity proj if dims differ\n",
    "        self.need_proj = (input_dim != output_dim)\n",
    "        if self.need_proj:\n",
    "            self.proj = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        identity = x\n",
    "        x = self.linear(x)\n",
    "        x = self.ls(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.act(x)\n",
    "        x = self.drop(x)\n",
    "        if self.need_proj:\n",
    "            identity = self.proj(identity)\n",
    "        return x + identity\n",
    "\n",
    "class ImprovedMLPClassifier3(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        hidden_dims: List[int],\n",
    "        output_dim: int,\n",
    "        dropout_rate: float = 0.3,\n",
    "        weight_decay: float = 1e-4,\n",
    "        label_smoothing: Optional[float] = None,\n",
    "        loss_fn: Optional[nn.Module] = None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.initial_bn = nn.BatchNorm1d(input_dim)\n",
    "        # build hidden blocks\n",
    "        dims = [input_dim] + hidden_dims\n",
    "        blocks = []\n",
    "        for i in range(len(dims)-1):\n",
    "            blocks.append(\n",
    "                ImprovedMLPBlock3(\n",
    "                    input_dim=dims[i],\n",
    "                    output_dim=dims[i+1],\n",
    "                    dropout_rate=dropout_rate\n",
    "                )\n",
    "            )\n",
    "        self.hidden_net = nn.Sequential(*blocks)\n",
    "        self.output_proj = nn.Linear(dims[-1], output_dim)\n",
    "\n",
    "        # loss with optional label smoothing\n",
    "        if loss_fn is not None:\n",
    "            self.loss_fn = loss_fn\n",
    "        else:\n",
    "            if label_smoothing:\n",
    "                self.loss_fn = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
    "            else:\n",
    "                self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                # Xavier uniform works well with GELU\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                nn.init.constant_(m.weight, 1.0)\n",
    "                nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: torch.Tensor,\n",
    "        labels: Optional[torch.Tensor] = None,\n",
    "        return_dict: bool = True,\n",
    "        **kwargs\n",
    "    ) -> SequenceClassifierOutput:\n",
    "        # flatten if needed\n",
    "        if input_ids.ndim > 2:\n",
    "            input_ids = input_ids.view(input_ids.size(0), -1)\n",
    "\n",
    "        x = self.initial_bn(input_ids)\n",
    "        x = self.hidden_net(x)\n",
    "        logits = self.output_proj(x)\n",
    "\n",
    "        loss = self.loss_fn(logits, labels) if labels is not None else None\n",
    "\n",
    "        if not return_dict:\n",
    "            return (logits, loss) if loss is not None else (logits,)\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=None,\n",
    "            attentions=None\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "rT6Pvr7rWNDJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model architecture: hdim_3072x1536x768\n",
      "Input dim: 3072, Output dim: 50\n"
     ]
    }
   ],
   "source": [
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "\n",
    "# SIMPLE AND FAST MLP FOR QUICK TRAINING\n",
    "class FastMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims, output_dim, dropout_rate=0.2):\n",
    "        super(FastMLP, self).__init__()\n",
    "        \n",
    "        # Simple architecture without complex blocks\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        \n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_rate)\n",
    "            ])\n",
    "            prev_dim = hidden_dim\n",
    "        \n",
    "        layers.append(nn.Linear(prev_dim, output_dim))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "        self.loss_fn = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    \n",
    "    def forward(self, input_ids, labels=None):\n",
    "        logits = self.network(input_ids)\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss = self.loss_fn(logits, labels)\n",
    "        \n",
    "        return SequenceClassifierOutput(loss=loss, logits=logits)\n",
    "\n",
    "# ORIGINAL COMPLEX MODEL (commented out for comparison)\n",
    "class ImprovedMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims, output_dim, dropout_rate=0.3):\n",
    "        super(ImprovedMLP, self).__init__()\n",
    "\n",
    "        self.input_bn = nn.BatchNorm1d(input_dim)\n",
    "\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "\n",
    "        # Costruisci più livelli nascosti\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(prev_dim, hidden_dim))\n",
    "            layers.append(nn.BatchNorm1d(hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "            prev_dim = hidden_dim\n",
    "\n",
    "        self.hidden_layers = nn.Sequential(*layers)\n",
    "        self.output_layer = nn.Linear(prev_dim, output_dim)\n",
    "        self.loss_fn = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "    def forward(self, input_ids, labels=None):\n",
    "        x = self.input_bn(input_ids)  # Normalizzazione del batch\n",
    "        x = self.hidden_layers(x)\n",
    "        logits = self.output_layer(x)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss = self.loss_fn(logits, labels)\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits\n",
    "        )\n",
    "\n",
    "input_dim = len(dataset[\"train\"][0][\"embedding\"])\n",
    "labels = np.unique(dataset['test'][TARGET_COLUMN])\n",
    "output_dim = len(labels)\n",
    "\n",
    "# FASTER TRAINING: Use smaller, simpler architecture\n",
    "hidden_dims = [3072, 1536, 768] # Reduced from [3072, 1536, 768]\n",
    "\n",
    "model = AdvancedMLPClassifier(input_dim, hidden_dims, output_dim, loss_fn=loss_fn)\n",
    "\n",
    "hidden_str = \"hdim_\" + \"x\".join(map(str, hidden_dims))\n",
    "print(f\"Model architecture: {hidden_str}\")\n",
    "print(f\"Input dim: {input_dim}, Output dim: {output_dim}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "8Rb1JSDataCd"
   },
   "outputs": [],
   "source": [
    "current_time = datetime.now()\n",
    "\n",
    "run_name = f\"AdvancedMLPClassifier_{hidden_str}_{current_time.strftime('%Y-%m-%d_%H-%M-%S')}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.rename_columns({\n",
    "    'embedding': 'input_ids',   # solo se è un array di interi!\n",
    "    TARGET_COLUMN: 'labels'       # target\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "id": "Jy3iQFUfy_x7",
    "outputId": "f055eb9f-e053-4759-8e1f-0b907e41fd40"
   },
   "outputs": [],
   "source": [
    "from transformers import EarlyStoppingCallback\n",
    "output_dir=f\"/equilibrium/datasets/TCGA-histological-data/lung/checkpoints/{run_name}\"\n",
    "\n",
    "\n",
    "wandb.init(\n",
    "    project=\"scTumorClassification\",  \n",
    "    group=SUB_GROUP,                       \n",
    "    name=run_name,\n",
    "    tags=[TARGET_COLUMN, str(PERCENTAGE)]\n",
    ")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = logits.argmax(axis=-1)\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    f1 = f1_score(labels, predictions, average=\"weighted\")\n",
    "    return {\"accuracy\": acc, \"f1\": f1}\n",
    "\n",
    "# OPTIMIZED TRAINING ARGUMENTS FOR FASTER TRAINING\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    \n",
    "    # REDUCED EPOCHS - most important change\n",
    "    num_train_epochs=150,  # Reduced from 400 to 50\n",
    "    \n",
    "    # EVALUATION STRATEGY - evaluate every N steps instead of every epoch\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=200,  # Evaluate every 200 steps instead of every epoch\n",
    "    \n",
    "    # SAVING STRATEGY - save less frequently\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=400,  # Save every 500 steps\n",
    "    save_total_limit=3,  # Keep only 3 best checkpoints\n",
    "    \n",
    "    # BATCH SIZE - you can try increasing this if you have GPU memory\n",
    "    per_device_train_batch_size=1024,  #\n",
    "    per_device_eval_batch_size=1024,  \n",
    "    \n",
    "    # LEARNING RATE - slightly higher since we have fewer epochs\n",
    "    learning_rate=1e-3,  # Increased from 5e-4 to 1e-3\n",
    "    \n",
    "    # LOGGING - reduce logging frequency\n",
    "    logging_steps=100,  # Log every 100 steps\n",
    "    \n",
    "    # OTHER OPTIMIZATIONS\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",  # Use F1 score as primary metric\n",
    "    greater_is_better=True,\n",
    "    report_to=\"wandb\",\n",
    "    remove_unused_columns=True,\n",
    "    optim=\"adamw_torch\",\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.1,\n",
    "    fp16=True,\n",
    "    dataloader_num_workers=8,\n",
    "    run_name=run_name,\n",
    "    \n",
    "    # DISABLE SOME OVERHEAD\n",
    "    dataloader_pin_memory=True,  # Faster data loading\n",
    "    ignore_data_skip=True,  # Skip data loading optimizations\n",
    ")\n",
    "\n",
    "# EARLY STOPPING - more aggressive to prevent overfitting\n",
    "early_stopping_callback = EarlyStoppingCallback(\n",
    "    early_stopping_patience=10,  # Reduced from 10 to 5\n",
    "    early_stopping_threshold=0.001  # Stop if improvement < 0.1%\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "lUiVLdiKWPel",
    "outputId": "9300242b-9692-4e85-d06d-59294e4585a3"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[early_stopping_callback],\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "# trainer.train(resume_from_checkpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bDgjlsFKeeMZ"
   },
   "outputs": [],
   "source": [
    "\n",
    "def log_confusion_matrix(y_true_ids, y_pred_ids, ds, column_name, title):\n",
    "    # Usa ClassLabel se presente\n",
    "    label_feature = ds.features[column_name]\n",
    "   \n",
    "    if hasattr(label_feature, \"int2str\"):\n",
    "        num_classes = label_feature.num_classes\n",
    "        class_names = [label_feature.int2str(i) for i in range(num_classes)]\n",
    "    else:\n",
    "        # fallback: nomi generici\n",
    "        num_classes = len(np.unique(y_true_ids))\n",
    "        class_names = [str(i) for i in range(num_classes)]\n",
    "    \n",
    "    cm = confusion_matrix(y_true_ids, y_pred_ids, labels=range(num_classes))\n",
    "    cm_percent = cm.astype(float) / cm.sum(axis=1, keepdims=True) * 100\n",
    "    cm_annot = np.empty_like(cm, dtype=object)\n",
    "    \n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            if cm.sum(axis=1)[i] > 0:\n",
    "                # Changed format: percentage first, then count in parentheses\n",
    "                cm_annot[i, j] = f\"{cm_percent[i, j]:.1f}%\\n({cm[i, j]})\"\n",
    "            else:\n",
    "                cm_annot[i, j] = f\"0.0%\\n({cm[i, j]})\"\n",
    "    \n",
    "    plt.figure(figsize=(max(8, len(class_names)*0.5), max(6, len(class_names)*0.4)))\n",
    "    \n",
    "    # Calculate font size based on number of classes to prevent overlap\n",
    "    font_size = max(6, min(12, 80 / len(class_names)))\n",
    "    \n",
    "    sns.heatmap(cm_percent, annot=cm_annot, fmt='', cmap='Blues',\n",
    "                xticklabels=class_names,\n",
    "                yticklabels=class_names,\n",
    "                cbar=False,\n",
    "                annot_kws={\"fontsize\": font_size, \"ha\": \"center\", \"va\": \"center\"})\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.tight_layout()\n",
    "    wandb.log({title: wandb.Image(plt)})\n",
    "    plt.close()\n",
    "\n",
    "# === 3. Predizione su validation set ===\n",
    "val_preds = trainer.predict(dataset[\"validation\"])\n",
    "val_y_true = val_preds.label_ids\n",
    "val_y_pred = np.argmax(val_preds.predictions, axis=1)\n",
    "log_confusion_matrix(val_y_true, val_y_pred, dataset['validation'], TARGET_COLUMN, title=f\"{SUB_GROUP} - Validation\")\n",
    "\n",
    "# === 4. Predizione su test set ===\n",
    "test_preds = trainer.predict(dataset[\"test\"])\n",
    "test_y_true = test_preds.label_ids\n",
    "test_y_pred = np.argmax(test_preds.predictions, axis=1)\n",
    "log_confusion_matrix(test_y_true, test_y_pred, dataset['test'], TARGET_COLUMN, title=f\"{SUB_GROUP} - Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M3igf4MFS_YS"
   },
   "outputs": [],
   "source": [
    "output_dir = f\"saved_models/{run_name}\"\n",
    "trainer.save_model(output_dir)\n",
    "\n",
    "artifact = wandb.Artifact(name=run_name, type=\"model\")\n",
    "artifact.add_dir(output_dir)\n",
    "wandb.log_artifact(artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Tmzq6tGcUhD"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvincenzo-civale\u001b[0m (\u001b[33mvincenzo-civale-universi-degli-studi-di-firenze\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/vcivale/scFoundation3/wandb/run-20250705_150526-ui5pn4ty</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vincenzo-civale-universi-degli-studi-di-firenze/scTumorClassification/runs/ui5pn4ty' target=\"_blank\">AdvancedMLPClassifier_hdim_1024x512_2025-07-05_11-47-25</a></strong> to <a href='https://wandb.ai/vincenzo-civale-universi-degli-studi-di-firenze/scTumorClassification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vincenzo-civale-universi-degli-studi-di-firenze/scTumorClassification' target=\"_blank\">https://wandb.ai/vincenzo-civale-universi-degli-studi-di-firenze/scTumorClassification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vincenzo-civale-universi-degli-studi-di-firenze/scTumorClassification/runs/ui5pn4ty' target=\"_blank\">https://wandb.ai/vincenzo-civale-universi-degli-studi-di-firenze/scTumorClassification/runs/ui5pn4ty</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run_name = \"AdvancedMLPClassifier_hdim_1024x512_2025-07-05_11-47-25\"\n",
    "# output_dir=f\"/equilibrium/datasets/TCGA-histological-data/lung/checkpoints/{run_name}/checkpoint-106953/\"\n",
    "\n",
    "# input_dim = len(dataset[\"train\"][0][\"input_ids\"])\n",
    "# labels = np.unique(dataset['test'][\"labels\"])\n",
    "# output_dim = len(labels)\n",
    "# hidden_dims = [1024, 512]\n",
    "\n",
    "# # === Ricarica modello ===\n",
    "# model = AdvancedMLPClassifier(input_dim, hidden_dims, output_dim, loss_fn=loss_fn)\n",
    "# from safetensors.torch import load_file\n",
    "# model.load_state_dict(load_file(f\"{output_dir}/model.safetensors\"))\n",
    "# model.eval()\n",
    "\n",
    "# # === Ricarica Trainer (senza training) ===\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=output_dir,\n",
    "#     per_device_eval_batch_size=256,\n",
    "#     dataloader_num_workers=16,\n",
    "#     report_to=\"wandb\",\n",
    "# )\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args\n",
    "# )\n",
    "\n",
    "# # === Funzione per plottare matrice di confusione ===\n",
    "# def log_confusion_matrix(y_true_ids, y_pred_ids, ds, column_name, title):\n",
    "#     # Usa ClassLabel se presente\n",
    "#     label_feature = ds.features[column_name]\n",
    "   \n",
    "#     if hasattr(label_feature, \"int2str\"):\n",
    "#         num_classes = label_feature.num_classes\n",
    "#         class_names = [label_feature.int2str(i) for i in range(num_classes)]\n",
    "#     else:\n",
    "#         # fallback: nomi generici\n",
    "#         num_classes = len(np.unique(y_true_ids))\n",
    "#         class_names = [str(i) for i in range(num_classes)]\n",
    "    \n",
    "#     cm = confusion_matrix(y_true_ids, y_pred_ids, labels=range(num_classes))\n",
    "#     cm_percent = cm.astype(float) / cm.sum(axis=1, keepdims=True) * 100\n",
    "#     cm_annot = np.empty_like(cm, dtype=object)\n",
    "    \n",
    "#     for i in range(cm.shape[0]):\n",
    "#         for j in range(cm.shape[1]):\n",
    "#             if cm.sum(axis=1)[i] > 0:\n",
    "#                 # Changed format: percentage first, then count in parentheses\n",
    "#                 cm_annot[i, j] = f\"{cm_percent[i, j]:.1f}%\\n({cm[i, j]})\"\n",
    "#             else:\n",
    "#                 cm_annot[i, j] = f\"0.0%\\n({cm[i, j]})\"\n",
    "    \n",
    "#     plt.figure(figsize=(max(8, len(class_names)*0.5), max(6, len(class_names)*0.4)))\n",
    "    \n",
    "#     # Calculate font size based on number of classes to prevent overlap\n",
    "#     font_size = max(6, min(12, 80 / len(class_names)))\n",
    "    \n",
    "#     sns.heatmap(cm_percent, annot=cm_annot, fmt='', cmap='Blues',\n",
    "#                 xticklabels=class_names,\n",
    "#                 yticklabels=class_names,\n",
    "#                 cbar=False,\n",
    "#                 annot_kws={\"fontsize\": font_size, \"ha\": \"center\", \"va\": \"center\"})\n",
    "#     plt.title(title)\n",
    "#     plt.xlabel(\"Predicted\")\n",
    "#     plt.ylabel(\"True\")\n",
    "#     plt.tight_layout()\n",
    "#     wandb.log({title: wandb.Image(plt)})\n",
    "#     plt.close()\n",
    "\n",
    "# # === Inizializza wandb ===\n",
    "# wandb.init(\n",
    "#     project=\"scTumorClassification\",\n",
    "#     group=SUB_GROUP,\n",
    "#     name=run_name,\n",
    "#     tags=[TARGET_COLUMN, str(PERCENTAGE)],\n",
    "#     resume=\"allow\",\n",
    "# )\n",
    "\n",
    "# # === Predizione e plot su validation ===\n",
    "# val_preds = trainer.predict(dataset[\"validation\"])\n",
    "# val_y_true = val_preds.label_ids\n",
    "# val_y_pred = np.argmax(val_preds.predictions, axis=1)\n",
    "# log_confusion_matrix(val_y_true, val_y_pred, dataset[\"validation\"], column_name=\"labels\", title=f\"{SUB_GROUP} - Validation\")\n",
    "\n",
    "# # === Predizione e plot su test ===\n",
    "# test_preds = trainer.predict(dataset[\"test\"])\n",
    "# test_y_true = test_preds.label_ids\n",
    "# test_y_pred = np.argmax(test_preds.predictions, axis=1)\n",
    "# log_confusion_matrix(test_y_true, test_y_pred, dataset[\"test\"], column_name=\"labels\", title=f\"{SUB_GROUP} - Test\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00580d6913cf4e63ac165103732de46a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1f464492f53344ec909bc309c8c0f8fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "30631e65e3f5416783a78d0b949de91f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "401e9de9d844443a88d2ca86688914b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7e575232172d411db6956f35e762af34",
      "placeholder": "​",
      "style": "IPY_MODEL_1f464492f53344ec909bc309c8c0f8fc",
      "value": " 38/38 [00:00&lt;00:00,  5.23it/s]"
     }
    },
    "52700863407645709f492daa095a82dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "533f7134544745f7a26e25462ed12540": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5d5de10d92734585b78b0ce6346a02ef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5dace822801c4b85a10cd69be6136e6e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e7a3ca5d29a4405a5ec1b9bdcd533d5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "712f284628d2402baddeba7894c50f85": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5dace822801c4b85a10cd69be6136e6e",
      "placeholder": "​",
      "style": "IPY_MODEL_bb67c994fe5543e2b7fb50f4256fc006",
      "value": " 38/38 [00:00&lt;00:00, 4687.61it/s]"
     }
    },
    "77aa377ad0d646b69d525816c2af9508": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7e575232172d411db6956f35e762af34": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "81a7724c185340218f68a2e2ab48f06c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5d5de10d92734585b78b0ce6346a02ef",
      "max": 38,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fea6f4a0269a44fb8bfa550ce3dc52d8",
      "value": 38
     }
    },
    "8aa70dd6d0c541818f9ada29b4f0624a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9769b54d4ff3457ba26f5e9f87b7048b",
       "IPY_MODEL_db16deb3954a4fe584052ae804f2b3cc",
       "IPY_MODEL_9c101debc03140539cac02b383310906"
      ],
      "layout": "IPY_MODEL_ec429d5c60784ac7a73e6189a2cf48ee"
     }
    },
    "9769b54d4ff3457ba26f5e9f87b7048b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ace37ae1fbc040e18d97cdd0dcc9f8cf",
      "placeholder": "​",
      "style": "IPY_MODEL_b650efe9cd2c45ec8f36f2c9183a5158",
      "value": "Loading dataset shards: 100%"
     }
    },
    "9c101debc03140539cac02b383310906": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_533f7134544745f7a26e25462ed12540",
      "placeholder": "​",
      "style": "IPY_MODEL_de36653efa884fe9af62c130eebe49e6",
      "value": " 39/39 [00:00&lt;00:00, 1614.93it/s]"
     }
    },
    "ac4c06dacf2148ab83e80066bb776a82": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ace37ae1fbc040e18d97cdd0dcc9f8cf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b650efe9cd2c45ec8f36f2c9183a5158": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bb67c994fe5543e2b7fb50f4256fc006": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bdf7bc0862f5403cbc8d81035fa64c11": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bf9b88911a0341b7ab3315d4b45940c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c5667c95c7354f8b96c52e9d1d92d040",
       "IPY_MODEL_d4ebbcaf56f2487b887268faaeba0af5",
       "IPY_MODEL_712f284628d2402baddeba7894c50f85"
      ],
      "layout": "IPY_MODEL_bdf7bc0862f5403cbc8d81035fa64c11"
     }
    },
    "c5667c95c7354f8b96c52e9d1d92d040": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5e7a3ca5d29a4405a5ec1b9bdcd533d5",
      "placeholder": "​",
      "style": "IPY_MODEL_30631e65e3f5416783a78d0b949de91f",
      "value": "Resolving data files: 100%"
     }
    },
    "d4ebbcaf56f2487b887268faaeba0af5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_df73fbfa13404f70907a8b2819a24575",
      "max": 38,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ec7e27530bf642bea41e3ccdccd9717c",
      "value": 38
     }
    },
    "db16deb3954a4fe584052ae804f2b3cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ac4c06dacf2148ab83e80066bb776a82",
      "max": 39,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_77aa377ad0d646b69d525816c2af9508",
      "value": 39
     }
    },
    "dc65e1965da940319d39659aff0e2170": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de36653efa884fe9af62c130eebe49e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "df73fbfa13404f70907a8b2819a24575": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea3004c5e9f4452aa026eaaed8a08539": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ffd58efded7c4bbc8f3662f00a9edc88",
       "IPY_MODEL_81a7724c185340218f68a2e2ab48f06c",
       "IPY_MODEL_401e9de9d844443a88d2ca86688914b0"
      ],
      "layout": "IPY_MODEL_dc65e1965da940319d39659aff0e2170"
     }
    },
    "ec429d5c60784ac7a73e6189a2cf48ee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ec7e27530bf642bea41e3ccdccd9717c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fea6f4a0269a44fb8bfa550ce3dc52d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ffd58efded7c4bbc8f3662f00a9edc88": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_00580d6913cf4e63ac165103732de46a",
      "placeholder": "​",
      "style": "IPY_MODEL_52700863407645709f492daa095a82dc",
      "value": "Resolving data files: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
